{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70de0f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import timm\n",
    "\n",
    "# Cartella sorgente (con sottocartelle chiamate x,y)\n",
    "source_dir = './ruote_catalogate_def/'\n",
    "\n",
    "\n",
    "# Carica percorsi e label (x,y) dal nome della cartella\n",
    "def load_image_paths_and_labels(base_dir):\n",
    "    classes = sorted(os.listdir(base_dir))  # es. ['0_1', '1_0']\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for cls in classes:\n",
    "        cls_path = os.path.join(base_dir, cls)\n",
    "        if cls.startswith('.'):\n",
    "            continue\n",
    "        if not os.path.isdir(cls_path):\n",
    "            continue\n",
    "        # Estrai x,y\n",
    "        x, y = cls.split(',')\n",
    "        label = (int(x)/3, int(y)/3)\n",
    "        \n",
    "        # Cerca immagini\n",
    "        for img_file in glob.glob(os.path.join(cls_path, '*.*')):\n",
    "            image_paths.append(img_file)\n",
    "            labels.append(label)\n",
    "\n",
    "            # Visualizza l'immagine come la vedresti sul PC\n",
    "            #img_pre = Image.open(img_file)\n",
    "            #img_pre.show()\n",
    "            #img = ImageOps.exif_transpose(img_pre)  # ruota automaticamente in base all'EXIF\n",
    "            #img.show()  # apre l'immagine in una finestra\n",
    "            #return\n",
    "\n",
    "    return image_paths, labels\n",
    "\n",
    "# Carica tutto da ruote_catalogate_def\n",
    "all_paths, all_labels = load_image_paths_and_labels(source_dir)\n",
    "\n",
    "# Mischia mantenendo accoppiamenti\n",
    "combined = list(zip(all_paths, all_labels))\n",
    "random.shuffle(combined)\n",
    "split_idx = int(len(combined) * 0.7)\n",
    "train_data = combined[:split_idx]\n",
    "test_data  = combined[split_idx:]\n",
    "\n",
    "# Separa paths e labels\n",
    "train_paths, train_labels = zip(*train_data)\n",
    "test_paths,  test_labels  = zip(*test_data)\n",
    "train_paths, train_labels = list(train_paths), list(train_labels)\n",
    "test_paths,  test_labels  = list(test_paths),  list(test_labels)\n",
    "\n",
    "class WheelDataset(Dataset):\n",
    "    # salva quelle variabili come attributi della classe\n",
    "    def __init__(self, image_paths, labels, transform=None, edge_transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.edge_transform = edge_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.image_paths[idx]) # legge l'immagine\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # converte BGR a RGB, fondamentale per i modelli torch\n",
    "\n",
    "        # Edge detection\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) # converte a scala di grigi\n",
    "        #gray_rgb = np.stack([gray]*3, axis=-1)\n",
    "        edges = cv2.Canny(gray, 20, 60) # rilevamento bordi con Canny\n",
    "        edges_rgb = np.stack([edges]*3, axis=-1)  # convert to 3 channels per compatibilitÃ  con edge_transform\n",
    "\n",
    "        img = Image.fromarray(img) # converte a PIL Image\n",
    "        img = ImageOps.exif_transpose(img)\n",
    "        #gray_rgb = Image.fromarray(gray_rgb)\n",
    "        edges_rgb = Image.fromarray(edges_rgb)\n",
    "        edges_rgb = ImageOps.exif_transpose(edges_rgb)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            #gray_rgb = self.transform(gray_rgb)\n",
    "        if self.edge_transform:\n",
    "            edges_rgb = self.edge_transform(edges_rgb)\n",
    "\n",
    "        # Concatenate RGB image and edge image along channel dimension\n",
    "        combined = torch.cat((img, edges_rgb), dim=0) # concatenazione lungo la dimensione dei canali, avremo 6 canali\n",
    "\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return combined, label\n",
    "\n",
    "class CenterPadCrop:\n",
    "    \"\"\"Ridimensiona mantenendo aspect ratio e aggiunge padding centrato per ottenere quadrato finale\"\"\"\n",
    "    def __init__(self, final_size=256):\n",
    "        self.final_size = final_size\n",
    "\n",
    "    def __call__(self, img: Image.Image):\n",
    "        # --- Resize lato lungo a final_size ---\n",
    "        w, h = img.size\n",
    "        if h > w:\n",
    "            new_h = self.final_size\n",
    "            new_w = int(w * self.final_size / h)\n",
    "        else:\n",
    "            new_w = self.final_size\n",
    "            new_h = int(h * self.final_size / w)\n",
    "        img = img.resize((new_w, new_h), resample=Image.BILINEAR)\n",
    "\n",
    "        # --- Calcola padding per rendere quadrato centrato ---\n",
    "        pad_left = (self.final_size - new_w) // 2\n",
    "        pad_right = self.final_size - new_w - pad_left\n",
    "        pad_top = (self.final_size - new_h) // 2\n",
    "        pad_bottom = self.final_size - new_h - pad_top\n",
    "\n",
    "        # --- Applica padding ---\n",
    "        img = transforms.functional.pad(img, padding=(pad_left, pad_top, pad_right, pad_bottom), fill=0)\n",
    "\n",
    "        return img\n",
    "\n",
    "# --- Uso nella pipeline di trasformazioni ---\n",
    "transform_rgb = transforms.Compose([\n",
    "    CenterPadCrop(final_size=224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "edge_transform = transforms.Compose([\n",
    "    CenterPadCrop(final_size=224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = WheelDataset(train_paths, train_labels, transform=transform_rgb, edge_transform=edge_transform)\n",
    "test_dataset  = WheelDataset(test_paths, test_labels, transform=transform_rgb, edge_transform=edge_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Carichiamo il modello vit\n",
    "model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
    "\n",
    "# Cambiamo il primo layer per 6 canali (RGB + Edge RGB), mantenendo le altre impostazioni\n",
    "orig_conv = model.patch_embed.proj\n",
    "model.patch_embed.proj = nn.Conv2d(\n",
    "    in_channels=6,\n",
    "    out_channels=orig_conv.out_channels,\n",
    "    kernel_size=orig_conv.kernel_size,\n",
    "    stride=orig_conv.stride,\n",
    "    padding=orig_conv.padding,\n",
    "    bias=orig_conv.bias is not None\n",
    ")\n",
    "\n",
    "# Output layer per un valore regressivo\n",
    "model.head = nn.Linear(model.head.in_features, 2)\n",
    "\n",
    "class ViTRegressor(nn.Module):\n",
    "    def __init__(self, vit_model):\n",
    "        super().__init__()\n",
    "        self.vit = vit_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vit(x)\n",
    "        x = torch.sigmoid(x)  # output tra 0 e 1\n",
    "        return x\n",
    "\n",
    "model = ViTRegressor(model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c81132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fine-tuning setup per regressione su due valori ---\n",
    "criterion = nn.MSELoss()           \n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 1\n",
    "test_results = []    # qui salveremo le informazioni dell'ultima epoca\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # -------- Training --------\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.float().to(device)      # shape: [batch, 2]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)                 # shape: [batch, 2]\n",
    "\n",
    "        loss = criterion(outputs, labels)       # MSE su entrambi valori\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Training Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "\n",
    "    # -------- Evaluation --------\n",
    "    model.eval()\n",
    "    running_loss_test = 0.0\n",
    "    is_last_epoch = (epoch == num_epochs - 1)\n",
    "\n",
    "    print(\"\\n--- VALORI PREDETTI NEL TEST SET ---\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(\n",
    "            tqdm(test_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Testing\")\n",
    "        ):\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.float().to(device)        # shape: [1, 2] nel test\n",
    "\n",
    "            outputs = model(inputs)                   # shape: [1, 2]\n",
    "\n",
    "            pred_x, pred_y = outputs[0].cpu().numpy()\n",
    "            real_x, real_y = labels[0].cpu().numpy()\n",
    "\n",
    "            # Stampa predizione e valori reali\n",
    "            #if idx % 0 == 0:\n",
    "            #    print(f\"Ruota idx={idx} | \"\n",
    "            #        f\"Predetto=({pred_x:.4f}, {pred_y:.4f}) | \"\n",
    "            #        f\"Reale=({real_x:.4f}, {real_y:.4f})\")\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss_test += loss.item() * inputs.size(0)\n",
    "\n",
    "            if is_last_epoch:\n",
    "                test_results.append({\n",
    "                    \"path\": test_paths[idx],\n",
    "                    \"x_pred\": float(pred_x),\n",
    "                    \"y_pred\": float(pred_y),\n",
    "                    \"x_real\": float(real_x),\n",
    "                    \"y_real\": float(real_y),\n",
    "                })\n",
    "\n",
    "    test_loss = running_loss_test / len(test_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Test MSE: {test_loss:.4f}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
